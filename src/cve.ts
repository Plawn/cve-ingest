
import { Batcher, SimpleBatcher } from "./utils/batcher.ts";
import { ProgressHandler } from "./utils/progress.ts";
import { getDateChunks } from "./utils/utils.ts";
import { Counter, PoolExecutor } from "./utils/pool.ts";
import { client, db, newDb } from "./conf.ts";
import {
  BulkWriteResult,
  bytes,
  Chunk,
  CPEInfos,
  CVENVD,
  CVENVDResult,
  CVESearch,
  ExportedCVESearch,
  SetKeys,
} from "./utils/types.ts";
import { prepareDate, sha1Hex } from "./utils/format.ts";

const defaultValues = {
  cwe: "Unknown",
};

const cpes = db.collection("cpe");

const cves = newDb.collection("cves");
const infos = newDb.collection("infos");
const pageSize = 2000;

function addIfMissing(cve: CVESearch, key: SetKeys, value: string) {
  const e = cve[key];
  e.add(value);
}

function makeQueryId(criteria: string, versionInfo: string) {
  return sha1Hex(criteria + versionInfo);
}

function extractVendorAndProduct(cpe_uri: string) {
  const vendor = cpe_uri.split(":")[3];
  const product = cpe_uri.split(":")[4];
  return [vendor, product];
}

function handleDescription(cveNVD: CVENVD, cveSearch: CVESearch) {
  for (const description of cveNVD.descriptions) {
    if (description["lang"] == "en") { // only take english descriptions
      if ("summary" in cveSearch) {
        cveSearch["summary"] += ` ${description["value"]}`;
      } else {
        cveSearch["summary"] = description["value"];
      }
    }
  }
}

function handleV3Metrics(item: CVENVD, cve: CVESearch) {
  if ("cvssMetricV31" in item.metrics) {
    const v3 = selectCvssMetricsV3(item);
    const data = v3.cvssData;
    cve["impact3"] = {
      availability: data.availabilityImpact,
      confidentiality: data.confidentialityImpact,
      integrity: data.integrityImpact,
    };
    cve["exploitability3"] = {
      attackvector: data.attackVector,
      attackcomplexity: data.attackComplexity,
      privilegesrequired: data.privilegesRequired,
      userinteraction: data.userInteraction,
      scope: data.scope,
    };
    cve["cvss3"] = data.baseScore;
    cve["cvss3-vector"] = data.vectorString;
    cve["impactScore3"] = v3.impactScore;
    cve["exploitabilityScore3"] = v3.exploitabilityScore;
  }
}

function selectCvssMetricsV2(item: CVENVD) {
  return item.metrics.cvssMetricV2[0];
}

function selectCvssMetricsV3(item: CVENVD) {
  return item.metrics.cvssMetricV31[0];
}

function handleV2Metrics(item: CVENVD, cve: CVESearch) {
  cve["access"] = {};
  cve["impact"] = {};
  cve["cvss"] = null;
  if ("cvssMetricV2" in item.metrics) {
    const v2 = selectCvssMetricsV2(item);
    const data = v2.cvssData;
    cve["access"] = {
      authentication: data.authentication,
      complexity: data.accessComplexity,
      vector: data.accessVector,
    };
    cve["impact"] = {
      availability: data.availabilityImpact,
      confidentiality: data.confidentialityImpact,
      integrity: data.integrityImpact,
    };
    cve["cvss"] = data.baseScore;
    cve["exploitabilityScore"] = v2.exploitabilityScore;
    cve["impactScore"] = v2.impactScore;
    cve["cvss-time"] = item.lastModified;

    // # NVD JSON lacks the CVSS time which was present in the original XML format
    cve["cvss-vector"] = data.vectorString;
  }
}

function handleReferences(item: CVENVD, cveSearch: CVESearch) {
  cveSearch["references"] = item?.references.map((e) => e.url);
}

/**
 * Extracts the CWE and binds it to the cveSearch Side
 * @param cveNVD
 * @param cveSearch
 */
function handleCWE(cveNVD: CVENVD, cveSearch: CVESearch) {
  let localCWE = defaultValues.cwe;
  if ("weaknesses" in cveNVD) {
    // only take primary for now
    // TODO: add support for multiple CWE handling
    for (const i of cveNVD.weaknesses.filter((e) => e.type === "Primary")) {
      for (const values of i.description) {
        if (values.lang === "en") {
          localCWE = values.value;
        }
      }
    }
  }
  cveSearch.cwe = localCWE;
}

function stem(cpe_uri: string) {
  const cpe_arr = cpe_uri.split(":");
  const i = cpe_arr.slice(0, 5);
  return i.join(":");
}

type CpeMatch = {
  vulnerable: boolean;
  criteria: string;
  versionStartExcluding?: string;
  versionStartIncluding?: string;
  versionEndIncluding?: string;
  versionEndExcluding?: string;
  matchCriteriaId?: string;
};

async function prepareQuery(
  cpeuri: CpeMatch,
): Promise<[Record<string, unknown> | undefined, string]> {
  const query: any = {};
  let version_info = "";
  if ("versionStartExcluding" in cpeuri) {
    query.versionStartExcluding = cpeuri.versionStartExcluding;
    version_info += query.versionStartExcluding + "_VSE";
  }

  if ("versionStartIncluding" in cpeuri) {
    query.versionStartIncluding = cpeuri.versionStartIncluding;
    version_info += query.versionStartIncluding + "_VSI";
  }

  if ("versionEndExcluding" in cpeuri) {
    query.versionEndExcluding = cpeuri.versionEndExcluding;
    version_info += query.versionEndExcluding + "_VEE";
  }

  if ("versionEndIncluding" in cpeuri) {
    query.versionEndIncluding = cpeuri.versionEndIncluding;
    version_info += query.versionEndIncluding + "_VEI";
  }
  if (Object.keys(query).length > 0) {
    return [query, version_info];
  } else {
    return [undefined, version_info];
  }
}

/**
 * Todo => type the return of this
 * @param query
 * @returns
 */
function getCPEInfos(query: any): Promise<undefined | CPEInfos> {
  return cpes.findOne(query);
}

async function handleCPE(item: CVENVD, cve: CVESearch) {
  if ("configurations" in item) {
    for (const i of item.configurations.flatMap((e) => e.nodes)) {
      for (const cpeMatch of i.cpeMatch) {
        if (cpeMatch.vulnerable) {
          const [query, versionInfo] = await prepareQuery(cpeMatch);
          if (query) {
            query["id"] = makeQueryId(cpeMatch.criteria, versionInfo);
            const cpeInfos = await getCPEInfos(query);
            if (cpeInfos) {
              cpeInfos.cpe_name.map((e) => e.cpe23Uri)
                .forEach((cpe23Uri) => {
                  addIfMissing(cve, "vulnerable_product", cpe23Uri);
                  addIfMissing(cve, "vulnerable_configuration", cpe23Uri);
                  addIfMissing(
                    cve,
                    "vulnerable_configuration_stems",
                    stem(cpe23Uri),
                  );
                  const [vendor, product] = extractVendorAndProduct(cpe23Uri);
                  addIfMissing(cve, "vendors", vendor);
                  addIfMissing(cve, "products", product);
                  const preparedStem = stem(cpe23Uri);
                  addIfMissing(cve, "vulnerable_product_stems", preparedStem);
                });
            } else {
              // TODO: implem
            }
          }
        }
      }
    }
  }
}

async function handleOne(item: CVENVD): Promise<ExportedCVESearch> {
  const c = item;
  const cve = {
    id: c.id,
    assigner: item.sourceIdentifier,
    "Published": c.published,
    "Modified": c.lastModified,
    "last-modified": c.lastModified,
    vulnerable_configuration: new Set<string>(),
    vulnerable_product: new Set<string>(),
    vendors: new Set<string>(),
    products: new Set<string>(),
    vulnerable_product_stems: new Set<string>(),
    vulnerable_configuration_stems: new Set<string>(),
    cwe: defaultValues.cwe,
  } as CVESearch;
  handleDescription(item, cve);
  handleV3Metrics(item, cve);
  handleV2Metrics(item, cve);
  handleReferences(item, cve);
  handleCWE(item, cve);
  cve["vulnerable_configuration_cpe_2_2"] = [];

  await handleCPE(item, cve);
  // TODO: handle cpe

  const cv = {
    ...cve,
    vulnerable_product_stems: [...cve.vulnerable_product_stems],
    products: [...cve.products],
    vendors: [...cve.vendors],
    vulnerable_configuration: [...cve.vulnerable_configuration],
    vulnerable_product: [...cve.vulnerable_product],
    vulnerable_configuration_stems: [...cve.vulnerable_configuration_stems],
  };
  return { ...cv };
}

async function upsertCve(cve: ExportedCVESearch) {
  await cves.replaceOne(
    { id: cve.id },
    cve,
    { upsert: true },
  );
}

function countBulkOperations(result: BulkWriteResult) {
  const { insertedCount, modifiedCount, deletedCount, upsertedCount } = result;
  return (
    insertedCount + modifiedCount + deletedCount + upsertedCount
  );
}

async function flusher(batch: ExportedCVESearch[]) {
  const size = batch.length;
  if (size === 0) {
    return;
  }
  const start = new Date().getTime();
  const batchInsertResult = await cves.bulkWrite(batch.map((cve) => ({
    replaceOne: {
      filter: { id: cve.id },
      replacement: cve,
      upsert: true,
    },
  })));

  const end = new Date().getTime();
  console.log("batch insert took", end - start);
}

async function getCvesBetweenPaged(
  start: Date,
  end: Date,
  page: number,
  pageSize: number,
): Promise<CVENVDResult> {
  // for debug here
  const startString = prepareDate(start);
  const endString = prepareDate(end);
  // const endString = prepareDate(end);
  const startIndex = page * pageSize;
  const url =
    `https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate=${startString}&lastModEndDate=${endString}&startIndex=${startIndex}`;
  console.log("using url", url);
  const res = await fetch(url);
  const text = await res.text();
  try {
    const value = JSON.parse(text);
    return value;
  } catch (e) {
    console.error(res.status, text);
    throw e;
  }
}

async function* getCvesBetween(
  baseStart: Date,
  baseEnd: Date,
): AsyncGenerator<Chunk> {
  // should split start and end in chunks
  for (const [start, end] of getDateChunks(baseStart, baseEnd)) {
    let hasRemaining = true;
    let page = 0;

    while (hasRemaining) {
      const result = await getCvesBetweenPaged(start, end, page, pageSize);
      // if the result is exactly the size of the page then we waste one query
      hasRemaining = !(result.vulnerabilities.length < pageSize);
      const expectedPages = result.totalResults / pageSize;
      page++;
      yield { result, page, expectedPages, start, end, hasRemaining };
    }
  }
}

function getUpdatedCvesSince(start: Date) {
  const end = new Date();
  const cves = getCvesBetween(start, end);
  return cves;
}

// async function testLocal() {
//     const filename = "./one.json";
//     const base = await readBase(filename);
//     const all = base.map(async e => {
//         const result = await handleOne(e);
//         console.log(result);
//         await writeResult(result);
//         await upsertCve(result);
//     });
//     await Promise.all(all);
// }

const progressHandler = new ProgressHandler<Date>(
  async ({ start, end, total }) => {
    const now = new Date();
    console.log("one chunk done at", now);
    await infos.updateOne({ id: "cves" }, {
      // start and end have to be in same year so we can bucket chunks by year
      $push: {
        [`chunks.${start.getUTCFullYear()}`]: {
          start,
          end,
          at: now,
          itemCount: total,
        },
      },
    });
  },
);


export async function getMissingDataChunks() {

}

export async function getMissingDataChunksFor(year: number) {
  
}

/**
 * Returns the chunks to fetch
 *
 * TODO: this is not the correct implementation for now
 */
export async function getLastChunk() {
  const res = await infos.findOne({ id: "cves" });
  const k = Object.keys(res.chunks).sort().reverse();
  let lastKey: undefined | string = undefined;
  if (k.length > 0) {
    lastKey = k[0];
  }
  if (!lastKey) {
    return undefined;
  }
  const chunks: Array<any> = res.chunks[lastKey];
  if (chunks.length > 0) {
    chunks.sort((a, b) => a.end.getTime() - b.end.getTime());
    return chunks[0];
  }
  return undefined;
}

async function ensureChunksIntegrity(until: Date) {
  // check that all chunks exists unitl the "until" date
  // TODO: implem, that missing chunk is only from until -> now
}

async function ensureInfosExist() {
  const res = await infos.findOne({ id: "cves" });
  if (res) {
    return;
  }
  await infos.insertOne({
    id: "cves",
    chunks: {
      // years are automaticcally upserted
    },
  });
}

async function doOnePage(
  chunk: Chunk,
  counter: Counter,
  // pendingPages: Counter,
  batcher: Batcher<any>,
) {
  const {
    result,
    page,
    start: chunkSart,
    end: chunkEnd,
    expectedPages,
    hasRemaining,
  } = chunk;
  console.log("doing page", page, "of expected pages", expectedPages);
  const start = new Date().getTime();
  const re = result.vulnerabilities
    .map((c) =>
      handleOne(c.cve)
        .then((e) => {
          batcher.enqueue(e);
          counter.increment();
        })
    );
  await Promise.all(re);
  const end = new Date().getTime();
  const took = (end - start) / 1000;
  console.log(`page ${page} took ${took} s`);
  progressHandler.addChunk({
    itemCount: re.length,
    start: chunkSart,
    end: chunkEnd,
    done: !hasRemaining,
    count: page,
    getBucketId: () => `${chunkSart}${chunkEnd}`,
  });
}

const getGenerator = (newUpdate: Date, props?: UpdateProps) => {
  if (props) {
    return getCvesBetween(props.startDate, props.endDate);
  } else {
    return getUpdatedCvesSince(newUpdate);
  }
};

type UpdateProps = {
  startDate: Date;
  endDate: Date;
};

export async function populateCves(props?: UpdateProps) {
  // TODO: implem cleaner and not global client
  await client.connect();
  await ensureInfosExist(); // ensure collection exists in mongo

  const counter = new Counter();
  const newUpdate = new Date();
  const pool = new PoolExecutor(2);
  const start = new Date().getTime();
  const batchers: Batcher<any>[] = [];

  for await (const r of getGenerator(newUpdate, props)) {
    const batcher = new SimpleBatcher(1000, flusher);
    batchers.push(batcher);
    pool.do(() => doOnePage(r, counter, batcher));
  }
  console.log("all download done, waiting for handlers to finish");
  await pool.isEmpty();
  await Promise.all(batchers.map((e) => e.flush()));

  const end = new Date().getTime();
  const took = (end - start) / 1000;

  console.log(`done: ${counter.get()} in ${took} s`);
  console.log(`did ${counter.get() / took} items/s`);

  await ensureChunksIntegrity(newUpdate); // checking that all the data does exist

  await client.close();
}
